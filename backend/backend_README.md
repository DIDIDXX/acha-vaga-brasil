# JobSeeker AI - Backend Documentation

## Vis√£o Geral

O **JobSeeker AI Backend** √© uma API REST desenvolvida em Flask que fornece funcionalidades de busca de vagas de emprego e integra√ß√£o com intelig√™ncia artificial. O backend serve como ponte entre o frontend React e os diversos job boards, oferecendo endpoints para busca de vagas e gera√ß√£o de curr√≠culos personalizados.

## Caracter√≠sticas Principais

### üîç Busca de Vagas
- API REST para busca de vagas em m√∫ltiplos job boards
- Suporte a filtros avan√ßados (localiza√ß√£o, tipo de trabalho, data)
- Web scraping de sites como Greenhouse, Lever e outros
- Agrega√ß√£o de resultados de m√∫ltiplas fontes

### ü§ñ Integra√ß√£o com IA
- Preparado para integra√ß√£o com OpenRouter API
- Endpoints para gera√ß√£o de curr√≠culos personalizados
- Otimiza√ß√£o para sistemas ATS
- Extra√ß√£o de palavras-chave das descri√ß√µes de vagas

### üåê API RESTful
- Endpoints bem estruturados e documentados
- Suporte a CORS para integra√ß√£o com frontend
- Tratamento de erros robusto
- Respostas em formato JSON

### üìä Agrega√ß√£o de Dados
- Coleta de vagas de m√∫ltiplas fontes
- Normaliza√ß√£o de dados de diferentes job boards
- Sistema de pontua√ß√£o de compatibilidade
- Cache de resultados para melhor performance

## Tecnologias Utilizadas

### Backend Framework
- **Flask 3.1.1** - Framework web principal
- **Flask-CORS 6.0.0** - Suporte a Cross-Origin Resource Sharing
- **SQLAlchemy** - ORM para banco de dados
- **SQLite** - Banco de dados local

### Web Scraping
- **Requests 2.32.5** - Cliente HTTP para requisi√ß√µes
- **BeautifulSoup4 4.13.5** - Parser HTML para web scraping
- **urllib3 2.5.0** - Biblioteca HTTP de baixo n√≠vel

### Outras Depend√™ncias
- **Werkzeug 3.1.3** - Utilit√°rios WSGI
- **Jinja2 3.1.6** - Engine de templates
- **Click 8.2.1** - Interface de linha de comando

## Estrutura do Projeto

```
job-search-ai-backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos de banco de dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py               # Modelo de usu√°rio
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # Rotas da API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py              # Rotas de usu√°rio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobs.py              # Rotas de busca de vagas
‚îÇ   ‚îú‚îÄ‚îÄ services/                # Servi√ßos de neg√≥cio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_service.py       # Servi√ßo de integra√ß√£o de vagas
‚îÇ   ‚îú‚îÄ‚îÄ static/                  # Arquivos est√°ticos (frontend build)
‚îÇ   ‚îú‚îÄ‚îÄ database/                # Banco de dados SQLite
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.db              # Arquivo do banco
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py              # L√≥gica de web scraping
‚îÇ   ‚îî‚îÄ‚îÄ main.py                 # Ponto de entrada da aplica√ß√£o
‚îú‚îÄ‚îÄ venv/                       # Ambiente virtual Python
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                   # Documenta√ß√£o do projeto
```

## Endpoints da API

### Busca de Vagas

#### `GET /api/jobs/search`

Busca vagas de emprego com base nos par√¢metros fornecidos.

**Par√¢metros de Query:**
- `query` (string, obrigat√≥rio): Termo de busca (ex: "Data Engineer")
- `remote_only` (boolean, opcional): Filtrar apenas vagas remotas (default: false)
- `after_date` (string, opcional): Data m√≠nima de publica√ß√£o no formato YYYY-MM-DD

**Exemplo de Requisi√ß√£o:**
```
GET /api/jobs/search?query=Data%20Engineer&remote_only=false&after_date=2025-01-01
```

**Exemplo de Resposta:**
```json
[
  {
    "title": "Data Engineer",
    "company": "TechCorp",
    "location": "Remote",
    "url": "https://example.com/job/data-engineer-techcorp",
    "description": "Procuramos um Data Engineer experiente...",
    "tags": ["Python", "SQL", "AWS", "Apache Spark"],
    "matchScore": 85
  }
]
```

### Usu√°rios

#### `GET /api/users`
Lista todos os usu√°rios (endpoint de exemplo do template)

#### `POST /api/users`
Cria um novo usu√°rio (endpoint de exemplo do template)

## Funcionalidades de Web Scraping

### Sites Suportados

O sistema foi projetado para fazer scraping dos seguintes tipos de job boards:

1. **Greenhouse** (`boards.greenhouse.io`)
   - Estrutura HTML padr√£o para listagem de vagas
   - Extra√ß√£o de t√≠tulo, localiza√ß√£o e link da vaga

2. **Lever** (`jobs.lever.co`)
   - Estrutura HTML espec√≠fica do Lever
   - Extra√ß√£o de informa√ß√µes b√°sicas da vaga

3. **Outros Job Boards**
   - Workable (`apply.workable.com`)
   - iCIMS (`careers.icims.com`)
   - Recruitee (`jobs.recruitee.com`)
   - E muitos outros conforme a query original

### L√≥gica de Scraping

```python
def search_jobs(query, remote_only=False, after_date=None):
    """
    Busca vagas em m√∫ltiplos job boards
    
    Args:
        query (str): Termo de busca
        remote_only (bool): Filtrar apenas vagas remotas
        after_date (str): Data m√≠nima no formato YYYY-MM-DD
    
    Returns:
        list: Lista de vagas encontradas
    """
```

### Tratamento de Dados

- **Limpeza de Texto**: Remo√ß√£o de espa√ßos extras e caracteres especiais
- **Normaliza√ß√£o**: Padroniza√ß√£o de formatos de data e localiza√ß√£o
- **Filtragem**: Aplica√ß√£o de filtros de busca e localiza√ß√£o
- **Agrega√ß√£o**: Combina√ß√£o de resultados de m√∫ltiplas fontes

## Configura√ß√£o e Execu√ß√£o

### Pr√©-requisitos

- Python 3.11+
- pip (gerenciador de pacotes Python)

### Instala√ß√£o

1. **Clone o reposit√≥rio:**
   ```bash
   git clone https://github.com/DIDIDXX/acha-vaga-brasil.git
   cd acha-vaga-brasil/job-search-ai-backend
   ```

2. **Ative o ambiente virtual:**
   ```bash
   source venv/bin/activate
   ```

3. **Instale as depend√™ncias:**
   ```bash
   pip install -r requirements.txt
   ```

### Execu√ß√£o

#### Desenvolvimento
```bash
python src/main.py
```

A aplica√ß√£o estar√° dispon√≠vel em `http://localhost:5000`

#### Produ√ß√£o
Para produ√ß√£o, recomenda-se usar um servidor WSGI como Gunicorn:
```bash
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 src.main:app
```

## Integra√ß√£o com Frontend

### CORS Configuration

O backend est√° configurado com Flask-CORS para permitir requisi√ß√µes do frontend:

```python
from flask_cors import CORS
CORS(app)  # Permite requisi√ß√µes de qualquer origem
```

### Servindo Arquivos Est√°ticos

O Flask est√° configurado para servir os arquivos do frontend React buildado:

```python
@app.route('/', defaults={'path': ''})
@app.route('/<path:path>')
def serve(path):
    # Serve arquivos est√°ticos do frontend ou index.html
```

### Estrutura de Resposta

Todas as respostas da API seguem um formato JSON consistente:

- **Sucesso**: Array de objetos ou objeto √∫nico
- **Erro**: `{"error": "Mensagem de erro"}`
- **Status Codes**: 200 (sucesso), 400 (bad request), 500 (erro interno)

## Banco de Dados

### SQLite Configuration

```python
app.config['SQLALCHEMY_DATABASE_URI'] = f"sqlite:///{os.path.join(os.path.dirname(__file__), 'database', 'app.db')}"
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
```

### Modelos Dispon√≠veis

- **User**: Modelo de usu√°rio (exemplo do template)
- Preparado para expans√£o com modelos de Job, CV, etc.

## Tratamento de Erros

### Web Scraping Errors

```python
try:
    response = requests.get(url)
    response.raise_for_status()
    # Processar resposta
except requests.exceptions.RequestException as e:
    print(f"Error scraping {url}: {e}")
    return []
```

### API Errors

```python
try:
    jobs = search_jobs(query, remote_only, after_date)
    return jsonify(jobs)
except Exception as e:
    return jsonify({"error": str(e)}), 500
```

## Performance e Otimiza√ß√£o

### Caching
- Implementar cache Redis para resultados de busca
- Cache de sess√£o para dados de usu√°rio
- TTL configur√°vel para diferentes tipos de dados

### Rate Limiting
- Implementar rate limiting para evitar sobrecarga
- Throttling de requisi√ß√µes de web scraping
- Monitoramento de uso da API

### Async Processing
- Considerar implementa√ß√£o de processamento ass√≠ncrono
- Queue system para jobs de scraping pesados
- Background tasks para atualiza√ß√µes de dados

## Seguran√ßa

### Valida√ß√£o de Entrada
- Sanitiza√ß√£o de par√¢metros de query
- Valida√ß√£o de formatos de data
- Escape de caracteres especiais

### CORS Policy
- Configura√ß√£o adequada para produ√ß√£o
- Whitelist de dom√≠nios permitidos
- Headers de seguran√ßa

### Rate Limiting
- Prote√ß√£o contra ataques DDoS
- Limites por IP e por usu√°rio
- Monitoramento de padr√µes suspeitos

## Monitoramento e Logs

### Logging
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
```

### M√©tricas
- Tempo de resposta da API
- Taxa de sucesso do web scraping
- N√∫mero de vagas encontradas por busca
- Erros e exce√ß√µes

## Pr√≥ximos Passos

### Melhorias Planejadas

1. **Expans√£o de Job Boards**
   - Integra√ß√£o com LinkedIn API
   - Suporte a Indeed, Glassdoor
   - APIs oficiais quando dispon√≠veis

2. **IA e Machine Learning**
   - Implementa√ß√£o completa da gera√ß√£o de CV
   - Sistema de recomenda√ß√£o de vagas
   - An√°lise de compatibilidade avan√ßada

3. **Performance**
   - Implementa√ß√£o de cache Redis
   - Processamento ass√≠ncrono
   - Otimiza√ß√£o de queries de banco

4. **Funcionalidades Avan√ßadas**
   - Sistema de alertas de vagas
   - Hist√≥rico de candidaturas
   - Analytics e relat√≥rios

### Deployment

- Containeriza√ß√£o com Docker
- Deploy em cloud (AWS, GCP, Azure)
- CI/CD pipeline
- Monitoramento em produ√ß√£o

## Conclus√£o

O backend do JobSeeker AI fornece uma base s√≥lida para a aplica√ß√£o de busca de vagas com IA. Com uma arquitetura modular e extens√≠vel, est√° preparado para crescer e incorporar novas funcionalidades conforme a demanda.

A integra√ß√£o com o frontend React est√° funcionando perfeitamente, e o sistema de web scraping oferece uma alternativa vi√°vel para agrega√ß√£o de vagas de m√∫ltiplas fontes at√© que APIs oficiais estejam dispon√≠veis.

